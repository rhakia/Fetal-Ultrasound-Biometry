{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1udET7nLGNgLuW0utgR8t45px_fHAOU_A","timestamp":1767283619311}],"gpuType":"T4","mount_file_id":"1udET7nLGNgLuW0utgR8t45px_fHAOU_A","authorship_tag":"ABX9TyN008bNx7L6iRN5o2qVVFNm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["mount = '/content/gdrive'\n","from google.colab import drive\n","drive.mount(mount)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoA-Ole87C8s","executionInfo":{"status":"ok","timestamp":1767284006596,"user_tz":-330,"elapsed":26183,"user":{"displayName":"Rhakia","userId":"10096125493858568921"}},"outputId":"96c13154-b745-4ebb-deac-ff1e83fa71cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import cv2\n","import torch\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","def generate_heatmap(size, center, sigma=5):\n","    x = np.arange(0, size, 1)\n","    y = np.arange(0, size, 1)\n","    xx, yy = np.meshgrid(x, y)\n","    heatmap = np.exp(\n","        -((xx - center[0])**2 + (yy - center[1])**2) / (2 * sigma**2)\n","    )\n","    return heatmap\n","\n","\n","class FetalLandmarkDataset(Dataset):\n","    def __init__(self, img_dir, csv_path, img_size=256, sigma=5):\n","        self.df = pd.read_csv(csv_path)\n","        self.img_dir = img_dir\n","        self.img_size = img_size\n","        self.sigma = sigma\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","\n","        img_path = f\"{self.img_dir}/{row['image_name']}\"\n","        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        h, w = img.shape\n","\n","        img = cv2.resize(img, (self.img_size, self.img_size))\n","        img = img / 255.0\n","\n","        landmarks = [\n","            (row['ofd_1_x'], row['ofd_1_y']),\n","            (row['ofd_2_x'], row['ofd_2_y']),\n","            (row['bpd_1_x'], row['bpd_1_y']),\n","            (row['bpd_2_x'], row['bpd_2_y']),\n","        ]\n","\n","        heatmaps = []\n","        for x, y in landmarks:\n","            x = int(x * self.img_size / w)\n","            y = int(y * self.img_size / h)\n","            heatmaps.append(\n","                generate_heatmap(self.img_size, (x, y), self.sigma)\n","            )\n","\n","        heatmaps = np.stack(heatmaps)\n","\n","        return (\n","            torch.tensor(img).unsqueeze(0).float(),\n","            torch.tensor(heatmaps).float()\n","        )\n"],"metadata":{"id":"m8OVGWQP7yGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sanity check (optional)\n","dataset = FetalLandmarkDataset(\n","    img_dir=\"/content/gdrive/MyDrive/images\",\n","    csv_path=\"/content/gdrive/MyDrive/role_challenge_dataset_ground_truth.csv\"\n",")\n","\n","img, heatmaps = dataset[0]\n","\n","print(img.shape)        # should be [1, 256, 256]\n","print(heatmaps.shape)   # should be [4, 256, 256]\n"],"metadata":{"id":"di5ccf6hDrZE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class SimpleUNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(32, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(64, 32, 2, stride=2),\n","            nn.ReLU(),\n","\n","            nn.ConvTranspose2d(32, 16, 2, stride=2),\n","            nn.ReLU(),\n","        )\n","\n","        self.out = nn.Conv2d(16, 4, 1)\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return self.out(x)\n"],"metadata":{"id":"-45n-HJDEQPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = SimpleUNet().to(device)\n","model.load_state_dict(\n","    torch.load(\"hypothesis_final_full_saved_model.pth\", map_location=device)\n",")\n","model.eval()\n"],"metadata":{"id":"_5BwzKulV9uO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img, gt_heatmaps = dataset[0]\n","img = img.unsqueeze(0).to(device)\n","\n","with torch.no_grad():\n","    pred_heatmaps = model(img)\n","\n","print(\"GT heatmaps:\", gt_heatmaps.shape)\n","print(\"Pred heatmaps:\", pred_heatmaps.shape)\n"],"metadata":{"id":"dBCDuE-EXLbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I0IwL-izPdQd"},"execution_count":null,"outputs":[]}]}